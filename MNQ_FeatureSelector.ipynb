{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNu75Nr09Ta1npv3kwgl7F2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kojack84/FuturesTrainer/blob/main/MNQ_FeatureSelector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0jfZOswLx5k",
        "outputId": "f4e67d92-ca88-4e09-abe8-5dba0243562d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/gdrive/MyDrive/FuturesTrainer\"\n",
        "\n",
        "INPUT_CSV = f\"{BASE_DIR}/MNQ_Advanced_MFE_MAE.csv\"\n",
        "\n",
        "FEATURE_SELECTION_DIR = \"feature_selection_v1\"      # relative under BASE_DIR\n",
        "MODELS_DIR            = \"models_v1\"                # relative under BASE_DIR\n",
        "\n",
        "PROFIT_TARGETS = \"25,50,75,100\"\n",
        "STOP_SIZES_FSEL = \"50,100,150,200\"   # example for top_features\n",
        "STOP_SIZES_TRAIN = \"50,100,150,200\"  # keep in sync for train_models\n"
      ],
      "metadata": {
        "id": "1Ou9vrsMPIl6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/top_features.py --input \"{INPUT_CSV}\" --direction both --profit-targets {PROFIT_TARGETS} --stop-sizes {STOP_SIZES_FSEL} --max-features 50 --output-dir \"{FEATURE_SELECTION_DIR}\" --gdrive-root \"{BASE_DIR}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIuensiDT6q7",
        "outputId": "e4b503f4-f433-4dcf-eb6d-cf922d54ba82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial candidate features after filters: 54\n",
            "Number of (direction,T,S) configs: 32\n",
            "Config long_T25_S50: positives=133503, samples=503738\n",
            "Config long_T25_S100: positives=148894, samples=503738\n",
            "Config long_T25_S150: positives=153327, samples=503738\n",
            "Config long_T25_S200: positives=155009, samples=503738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES_FILE = f\"{BASE_DIR}/{FEATURE_SELECTION_DIR}/selected_features.txt\"\n",
        "\n",
        "!python /content/train_models.py --input \"{INPUT_CSV}\" --features \"{FEATURES_FILE}\" --direction both --profit-targets {PROFIT_TARGETS} --stop-sizes {STOP_SIZES_TRAIN} --n-splits 5 --min-positives 100 --threshold-min-trades 200 --output-dir \"{MODELS_DIR}\" --gdrive-root \"{BASE_DIR}\"\n"
      ],
      "metadata": {
        "id": "4kr0pmXPUCoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/FeatureTrainer\"\n",
        "MODELS_DIR = \"models_v1\"\n",
        "\n",
        "models_path = os.path.join(BASE_DIR, MODELS_DIR)\n",
        "thresholds_path = os.path.join(models_path, \"thresholds.json\")\n",
        "\n",
        "# 1) Load thresholds.json\n",
        "with open(thresholds_path, \"r\") as f:\n",
        "    thresholds_data = json.load(f)\n",
        "\n",
        "thr_df = pd.DataFrame(thresholds_data)\n",
        "\n",
        "# 2) Load all metrics_*.csv and aggregate basic stats\n",
        "metrics_files = glob.glob(os.path.join(models_path, \"metrics_*.csv\"))\n",
        "\n",
        "metrics_list = []\n",
        "for path in metrics_files:\n",
        "    m = pd.read_csv(path)\n",
        "    # metrics file already has: config_key, fold_index, auc, best_ev_per_trade, best_n_trades, etc.\n",
        "    # Aggregate per config_key\n",
        "    agg = (\n",
        "        m.groupby(\"config_key\")\n",
        "         .agg(\n",
        "             cv_auc_mean=(\"auc\", \"mean\"),\n",
        "             cv_auc_std=(\"auc\", \"std\"),\n",
        "             cv_ev_per_trade=(\"best_ev_per_trade\", \"mean\"),\n",
        "             cv_ev_std=(\"best_ev_per_trade\", \"std\"),\n",
        "             cv_trades_mean=(\"best_n_trades\", \"mean\"),\n",
        "             cv_trades_std=(\"best_n_trades\", \"std\"),\n",
        "         )\n",
        "         .reset_index()\n",
        "    )\n",
        "    metrics_list.append(agg)\n",
        "\n",
        "if metrics_list:\n",
        "    metrics_df = pd.concat(metrics_list, ignore_index=True)\n",
        "else:\n",
        "    metrics_df = pd.DataFrame(columns=[\n",
        "        \"config_key\", \"cv_auc_mean\", \"cv_auc_std\",\n",
        "        \"cv_ev_per_trade\", \"cv_ev_std\",\n",
        "        \"cv_trades_mean\", \"cv_trades_std\"\n",
        "    ])\n",
        "\n",
        "# 3) Merge thresholds_df (direction, T, S, best_threshold, cv_ev_per_trade etc.) with metrics_df\n",
        "# thresholds.json already has cv_ev_per_trade and AUC stats too, but we keep them and also bring in metric aggregates\n",
        "merged = thr_df.copy()\n",
        "\n",
        "# Build config_key to match metrics\n",
        "merged[\"config_key\"] = merged.apply(\n",
        "    lambda row: f\"{row['direction']}_T{int(row['profit_target'])}_S{int(row['stop_size'])}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "summary = pd.merge(\n",
        "    merged,\n",
        "    metrics_df,\n",
        "    on=\"config_key\",\n",
        "    how=\"left\",\n",
        "    suffixes=(\"_thr\", \"_m\")\n",
        ")\n",
        "\n",
        "# 4) Sort by primary objective: high EV, then high AUC, then more trades\n",
        "summary_sorted = summary.sort_values(\n",
        "    by=[\"cv_ev_per_trade_thr\", \"cv_auc_mean_thr\", \"cv_trades_mean_thr\"],\n",
        "    ascending=[False, False, False]\n",
        ")\n",
        "\n",
        "display(summary_sorted)\n",
        "\n",
        "# 5) Save to Drive for offline analysis (Excel, Sheets, etc.)\n",
        "summary_path = os.path.join(models_path, \"summary_configs.csv\")\n",
        "summary_sorted.to_csv(summary_path, index=False)\n",
        "print(f\"Saved summary to: {summary_path}\")\n"
      ],
      "metadata": {
        "id": "BYKzQ_1eUd3J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}